
 - 일반적인 랜더링 파이프라인

   모니터는 픽셀의 집합이며 우리는 전혀 보이진 않지만 개념상 월드라는 것(x, y, z로 이뤄진 세상)을 만들어 모니터에 출력하고자 한다.
   어떤 세상에 존재(아직 Mesh라는 것이 없는 것)가 있다는 것을 표현하려고 한다면, 우리 엔진에서는 이를 GameEngineTransform이 도와준다.
   어떤 점이 있다면, 이 점은 점이 바라보는 방향, 점의 위치, 점의 회전 값에 대한 집합(Worldmatrix)을 가지고 있다.
   이 정보만으로는 화면에 출력될 수 없다.
   그렇기 때문에 이 점(vertex)들을 모아(연결) 삼각형(mesh)로 만든다.
   이 삼각형의 각 점들이 우리가 만든 Worldmatrix(행렬)에 영향을 받게 된다.

   삼각형이 화면 가운데에 존재한다고 가정해보자.
   이것이 Worldmatrix에 영향을 받을 경우 크자이공부가 적용된다.
   또한 화면에 출력하기 위해 카메라를 하나 만든다.
   카메라는 화각, near, far 등의 정보를 갖고 뷰 -> 프로젝션 -> 뷰포트 작업을 한 뒤 모니터에 삼각형을 띄운다.
   이때 카메라가 정보를 통해 물체를 화면에 띄우기 전, 물체를 담는 공간을 피라미드(프로스텀)이라고 한다.
   프로스텀 안에 mesh를 가진 존재가 들어오면 뷰포트가 곱해지면서 화면에 위치하게 되는 것이다.
   프로스텀에 포함되지 않는 것들은 화면에 표시되지 않는다.
 
 - Direct의 랜더링 파이프라인

   GameEngineBase의 랜파.jpg를 보면서 확인
   맨 처음 단계 Input Assembler는 점을 준비하라는 뜻이다.

   최초에 화면에 점이 위치한다면, 이건 점이 Worldmatrix를 통해 위치만 결정된 것이다.
   아직 색에 대한 정보는 담고 있지 않다.
   사실 점은 위치 뿐만 아니라 여러 정보를 담을 수 있는데, 두 번째로 중요한 것이 바로 색깔 정보이다.
   화면에 특정 색을 갖는 존재가 표현된다면, 색을 가지고 있다. 이 색을 표현하기 위한 정보를 점이 가지고 있으며 안티얼라이어싱을 통해 색을 결정하는 것이다.
   이 점들을 만들어서 DirectX에게 전달해야 한다.

   지금까지는 점의 위치만 보낸 것이다. 물론 위치 정보는 필수이기 때문에 보내야 한다.
   
   이를 위해 GameEngineVertex를 추가하여 내부에 float4 Vertex, float4 Color를 추가한다.

 - 인스턴스 버퍼
   Input Assembler에 화살표 왼쪽으로 연결된 부분에서 인스턴스 버퍼란, DirectX에 넘길 정점을 그리기 위한 버퍼

 - 현재까지는 Vertex에서 점의 위치만 정보로 보냈다.
   점에는 위치 뿐만 아니라 색깔 등 여러가지 정보를 담을 수 있다.
   GameEngineVertex를 추가하여 위치와 정보에 대해 선언

 - 인덱스 버퍼
   점이 몇 개인지, 어떤 순서로 그릴지에 대한 정보를 넘겨주는 버퍼
 
 ------------------------------------------------------------------------------------------------------------------------------------------------------
   랜더링 파이프라인 EX (0411)

- 아직 Input Assembler1 단계가 끝나지 않았다.
  랜더링 파이프라인의 단계를 가지고 있는 클래스를 하나 선언 - GameEngineRenderingPipeLine

- 매쉬와 머터리얼은 3D 프로그래밍 라이브러리의 단계를 나눠서 하나의 개념으로 표현하기 위해 쓰는 말이다.
  실제로 랜파.jgp는 DirectX의 랜더링 파이프라인인데, Mesh와 Merterial이라는 개념이 존재하지 않는다.
  그래도 통용되서 쓰이는 개념에 따라 다렉 랜파의 단계를 묶어보면
  Mesh = Input Assembler1 / VertexShader / Input Assembler2 / 래스터라이저
  Merterial = PixelShader / Outmerger

- InputAssembler
  DeviceContext->IASetVertexBuffer()

  인자로 ID3D11Buffer를 넘겨준다.
  화면에 나오는, 색이 입혀지지 않은 도형을 생각해보자. 이 매쉬를 그리기 위해 점들을 생성하는 단계

- VertexShader
  DeviceContext->VSSetShader()

  정점 네 개로 이뤄진 rect를 그린다면, VertexShader는 네 번 동작한다.
  CoreResoucresInit() 함수를 확인해보면 rect는 네 개의 Vertex가 필요하다. 이 정보는 로컬 스페이스에 담겨있는 것이다.
  이 로컬 상의 점들에 대해 행렬을 통해 변환을 실시한다. 여기서 Projection까지 실시.

- Input Assembler2
  DeviceContext->IASetIndexBuffer()

  생성된 점들에 대해 어떤 순서로 이을지 (그릴지) 정한다.

-------------------------------------------------------------
- 여기서 부터는 화면에 출력되는 과정에 꼭 필요한 단계는 아니다.

- Hullshaer와 테셀레이션
  Vertex 쪼개기다.
  일반적으로 rect를 만들었다고 하면, 그게 변할리는 없다.
  근데 배틀그라운드에서 시야를 중간 정도로 한 뒤 굉장히 먼 곳을 바라보면 액터가 찌그려져서 보일 때가 있을 것이다.
  헐셰이더가 정점을 쪼개고, 테셀레이션이 그걸 토대로 매시를 비트는 것이다.
  어떤 액터를 표현하는데 최대 1000만개의 정점이 필요하다고 가정하면
  lod(Level of detail)에 따라 멀리서 볼때는 100만개로만 표현 이런 식으로 한다.
  매쉬를 단계에 따라 n개 만들 수 있다.

  1m = 1000만개
  10m = 100만개
  100m = 10만개
  1000m = 만개 

  이런 식으로 lod에 따라 달라지게 한다.

- 도메인 셰이더와 지오매트리 셰이더
  도메인 셰이더는 입자 처리, 지오메트리 셰이더는 버텍스 생성이다.

  이 단계에서는 없던 버텍스를 생성한다. 주로 파티클(입자) 생성에 활용하는 단계.
  파티클은 어마어마하게 많은 양의 동일한 버텍스를 화면에 뿌리는 것이다.

  지오메트리 단계에는 지오메트리 셰이더와 인스턴싱이 있는데, 인스턴싱이 조금 더 빠르나 사실 별로 의미없다(우리는 안배울 예정이라).
  도메인 셰이더에서 어떤 버텍스가 들어오면 특정한 정보를 부여하고, 지오메트리 셰이더가 이 정보가 담긴 버텍스를 더 만들어내고, 어떻게 그릴지 정한다.
  >> 이 과정(CoreResourcesInit())을 GPU한테 시킬 수 있음

---------------------------------------------------------------

- 래스터라이저
  DeviceContext->RSSetState()

  프로젝션까지 적용된 버텍스에 대해 w 나누기를 해주고
  뷰 포트 행렬을 곱해준다.
  화면 컬링(액터가 화면내에 출력되지 않고 짤려야 할 경우 컷하는 과정)도 해준다.
  또한 화면에 어떤 픽셀에 물체의 정보가 담겨야 하는지, 픽셀 건지기(선생님의 표현)도 해준다. 물체가 존재해야 하는 픽셀을 체크하는것

- 픽셀셰이더
  DeviceContext->PSSetShader

  건지기로 어떤 픽셀에 매쉬의 정보가 출력되야 하는지 알아냈다면, 이제 색깔 입히기를 해야한다.
  버텍스에 저장된 Color를 기반으로 색을 찍게 된다.

- 아웃풋머저
  DeviceContext->OMSetRenderTarget()
  어떤 랜더 타겟에 그릴 것인지 결정하는 단계

  픽셀 셰이더까지 실시하여 형태와 색이 정해졌다고 하자.
  우리는 이미지 로드를 실시할 때마다 HDC가 생성된다는 것을 알고 있다.
  아마 게임을 만들려고 한다면 수천개의 이미지를 로드한 상태, 이러면 HDC가 숫자만큼 수천개 존재하게 된다.
  픽셀 셰이더에 담긴 그려야하는 정보를 이 수천개의 이미지에서 어디에 그릴 지 정하는 것이다.
  우리는 BackBuffer용 랜더타겟을 만들어놨음
  그러면 TextureLoad 하여 특정하게 그려진 HDC가 BackBuffer에 복사되고 윈도우창에 출력됨

-------------------------------------------------------------------------------------
230421 랜파 총정리
// 현재의 구조에서 110왜 이미지가 뜨는가
// 
// RenderingPipeLineSetting 후
// Render 실시
// 
// 랜파는 비어있는 파이프와 같다.
// 세팅은 넣으면 슬롯에 고정되며, 다시 빠지지 않음
// 물론 새로운걸 만들어서 교체는 가능
// 
// <RenderingPipeLineSetting>
// 
// -1단계 // 초반부 //
// 
// 먼저 InputLayOut 실시
// 랜더링을 위해서는 점으로 면을 만드는게 기본이다.
// 근데 글카는 점의 정보를 모름
// 그래서 InputLayOut을 만들어서 전달해줘야함
// 이 점의 구성은 Vertex 클래스에 멤버 변수로 넣어둠
// 넣는 방법은 AddInputLayOut 실시
// 
// 이거 만들 때 문제가 하나 있음
// 인풋레이아웃 만들 때 쉐이더도 같이 있어야 한다.
// 쉐이더의 struct Input이 필요한 것
// 이걸 위해서 Vertexbuffer나 shaderbuffer가 모두 세팅됐을 때, InputLayOutPtr->ResCreate 실시
// 
// -2단계
// 
// 이제 점의 형식대로 만들어진 점 데이터가 필요함
// VertexBuffer가 담당하는 중
// 그 구조대로 만들어서 넣어줌(Core_Resources)
// 이걸 mesh라고 함
// 이걸 넘기면 쉐이더에서 이용한다.
// 
// -3단계
// 
// 사용자는 메쉬를 화면에 뭔가를 하여 띄우고 싶음
// 보통 크기를 확대한다고 할 때, 가로 세로 길이가 1인 사각형을 그대로 띄우면 점처럼 보일 것
// 이걸 관념상으로 보이게 해주는 것이 VertexShader
// VertexShader는 그것을 위해 상수 버퍼가 필요함 (행렬로 크자이를 정해줌)
// 만약 행렬을 쓰고 싶다고 한다면, DirectX는 이 정보를 모름. 이것을 상수 버퍼가 전달해주는 것
// Texture_VS에서 WorldViewProjectionMatrix를 mul 해줌
// 이걸 넣어주기 위해 Shader 클래스에서 ResCheck으로 상수 버퍼를 조사함
// GetResource 하고 switch문 드감
// 메모리를 아끼기 위해 CreateAndFind 실시.
// 상수 버퍼는 메모리가 똑같으면 돌려쓸 수 있어서 이게 가능
// 예시로, 64바이트 TransformData 있어? 하면 모든 mesh는 이걸 돌려쓸 수 있다는 것.
// 이후 Setter로 값을 적용한 뒤, ShaderResourceHelper에게 넘겨줌
// 
// -4단계
// 
// indexbuffer를 어떻게 써서 그릴지를 정한다.
// 먼저 그리는 순서에 대한 데이터를 넣어준다.
// vertex가 네갠데 이걸 0 1 2 0 2 3 이런 식으로, 어떻게 넣을지 정하는 것
// 여기서, 숫자를 몇 개씩 잘라서 넣을지 다이렉트는 모른다.
// 이걸 정해주는 것이 Topology
// 이 순서로 선을 그리는 건지, 몇 개씩 잘라서 넣는 건지를 정해주는 것이다.
// 우리는 TRIANGLELIST로 정했다.
// 
// -5단계 // 후반부 //
// 
// 4단계까지 한 점은 레스터라이저로 넘어간다.
// 레스터라이저는 굉장히 많은걸 한다.
// 앞면 뒷면 처리, 윈도우창 밖으로 넘어간 것, 깊이(누가 앞에 누가 뒤에 그려지는지), 뷰포트곱하고 w 나누기, 면인
// Core_Resources에서 하는데, 사실 별거 없다.
// w 나눠주는건 자동이다.
// FILLMODE(면으로? 와이어로?), CULLMODE(앞면? 뒷면?) 실시
// 우리는 솔리드(면)에 뒷면 안보이게 했다. CULLMODE에 NONE 하면 앞면 뒷면 다 보임. 지금은 BACK으로 했는데, 이건 뒷면 안보이게 하는 것(앞면만 suck 보임)
// 뷰포트는 MainCamera 클래스가 하고 있음
// 랜파가 뷰포트 가지고 있을 수도 있는데, 한 번 세팅하면 뷰포트는 바뀌지 않을 것이라 생각해서 Camera에서 했슴(GELevel::Render에서 실시)
// 근데 이 구조는 계속 Setting을 호출하기 때문에, 바꿔주는게 최적화에 좋다(아직 안바꿈).
// 
// -6단계
// 
// PixelShader는 VertexShader와 완전히 동일하게 세팅된다.
// 안에 있는 리소스도 똑같이 조사한다.
// 픽셀 쉐이더 단계는 화면에 뜨는 물체의 색을 결정하는 단계이다.
// ShaderResCheck에서 switch문에, 이게 텍스쳐다 하면 EngineBaseTex가 Load 된다.
// 이 과정에서 CreateShaderResourceView를 하는데(쉐이더리소스뷰), 사실 쉐이더리소스뷰 굉장히 어려운과정임
// 근데 우리는 DirectTexlib을 써서 쉐이더리소스뷰만들고 담아서 쓰는중
// 정보를 담아주는 구조체(Data, Image)를 활용함
// 이건 핸들을 얻는 과정인데, 내 이미지를 쉐이더에 세팅할 수 있음
// 쉐이더에서 이미지를 쓰고 싶다면 호출하는 VSSetShaderResource에 SRV를 넣어줌
// 앞서 리소스를 하나 로드한 상태(You Suck) <= 엔진 수준에서 이미 로드하게 만들어놨음
// 다음으로 Shader에 로드한 이미지를 써야한다고 세터로 세팅한다.
// 
// +) 쉐이더가 이런 텍스쳐 리소스나 상수버퍼 리소스를 가지고, 이 쉐이더가 포함되는 랜파를 랜더들이 공유한다면,
// 한 명만 바꾸는게 안된다. 쉐이더 조건을 바꾸면 공유하는 랜더들은 모두 영향을 받음.
// 
// SetTexture에서, Texture::Find(_Name)으로 찾아온 이미지를 TextureSetter.Res에 적용 가능.
// DiffuseTex를 "적용할이미지"로 세팅해줘가 됩니다.
// 
// 우리 구조에서는 샘플러가 만들어져있는 상태로 쉐이더가 컴파일되야한다는 것 뿐.
// 
// -7단계
// 
// 이제 그릴 단계
// 지금은 깊이 크게 의미 없어서 Depth는 안씀. 그냥 랜더링 한 순서대로 나온다.
// 다음은 Blend를 하는데, 이건 반투명 처리이다. 아직은 의미 없음
// 화면에 띄우는 행위는 RenderTarget, BackBuffer(SwapChain)이 중요하다.
// 화면중에 어디에 출력할 것인지를 정하는 것
// 카메라의 뷰포트와 같다. 무조건 swapchain 만들때 얻은 backbuffer에 출력할 건데, 이건 gameEngineDevice::RenderStart 에서 실시되고 있다.
// 근데 이게 가장 앞에 있는 것은, 지금 상황에서 BackBuffer에 안그리고 출력할리가 없기 때문.
// 다른 RenderTarget에 그려서 출력한다고 하면 할 수 있지만, 그건 아직 안만들었음.
// 
// SwapChain에서 Texture를 하나 빼옴 -> 그 Texture로 RenderTarget(여기에 그리라는 권한)을 만들었다.
// 우리는 여기에 그려라가 BackBuffer에 박혀있다는 뜻.
// 앞으로 1개월은 바뀔리 없음. 근데 왜바뀌는가~ 15개에 다 따로 그리고 모아서 효과를 주고 할 수 있는데, 미래의 이야기.
// 